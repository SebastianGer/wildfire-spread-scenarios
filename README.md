# Wildfire Spread Scenarios: Increasing Sample Diversity of Segmentation Diffusion Models with Training-Free Methods

This repository contains a cleaned-up version of the code used for the experiments in `Wildfire Spread Scenarios: Increasing Sample Diversity of Segmentation Diffusion Models with Training-Free Methods`, published at the Northern Lights Deep Learning Conference 2026. 

If you would like to use diversity-encouraging methods like Particle Guidance or SPELL in your own project, I recommend simply implementing yourself, following the respective papers. It's not much if you already have a working diffusion model implementation. If you want to re-run some experiments from the paper, follow the description below. 

## MMFire dataset

MMFire is an ambiguous segmentation dataset, meaning that it contains multiple possible outputs for each input. Be aware that the diversity in segmentation masks is not realistic. This dataset is only meant to be used as a tool for evaluating ambiguous segmentation tasks. Since the simulator used for predicing the wildfire spread based on given input data is a comparatively simple computer program, you should expect deep learning models to be able to learn to approximate this mapping rather well. This is very different from real-world observations where such a simple relationship is not known, and deep learning models currently perform much worse. 

To use the dataset in your own code, you can use the Lightning Datamodule at `src/firespreadscenarios/dataloader/SimfireDataModule.py` which directly provides dataset loaders for train/val/test set. In our code, the dataset is associated with the term `simfire`, because it was generated by the corresponding simulation environment [SimFire by MITRE](https://github.com/mitrefireline/simfire). To avoid confusion, we named the published dataset MMFire in the paper. 

## Setup 

Setting up the environment:

``` pip3 install -r requirements.txt ```

1. Download and prepare LIDC according to [https://github.com/gaozhitong/MoSE-AUSeg/](https://github.com/gaozhitong/MoSE-AUSeg/).
2. Download the Cityscapes dataset from [https://www.cityscapes-dataset.com/downloads/](https://www.cityscapes-dataset.com/downloads/) (`gtFine_trainvaltest.zip` and `leftImg8bit_trainvaltest.zip`).
3. Download the MMFire dataset from [https://doi.org/10.5281/zenodo.18037549](https://doi.org/10.5281/zenodo.18037549).
4. Add the corresponding paths in `cfgs/dataset_name/dataset.yaml`. 
5. If you want to use the probabilistic UNet, follow the setup instruction 'Adding KL divergence for Independent distribution' in [https://github.com/stefanknegt/Probabilistic-Unet-Pytorch](https://github.com/stefanknegt/Probabilistic-Unet-Pytorch).

Install the project as a local python project, to be able to import the files from `third_party/` from `src/`. If you already have installed packages with the same names as those under `third_party/`, that might lead to problems or damage of some kind, so do not do that. 

``` pip install -e . ```

## Re-running our experiments

We use wandb to log experimental results. This can be turned off by setting the environment variable `WANDB_MODE=disabled`. The results will then be logged to a local directory instead.

Experiments are parameterized via yaml files in the `cfgs` directory. Arguments are parsed via the [LightningCLI](https://lightning.ai/docs/pytorch/stable/cli/lightning_cli.html). Everything except training the base models is done via WandB sweeps. These sweeps are parameterized via yaml files  that are prefixed with `wandb_`. We omit explanations of how to use wandb sweeps to run experiments and refer the readers to the [original documentation](https://docs.wandb.ai/guides/sweeps). To run the same experiments without WandB, the parameters specified in the WandB sweep configuration file can simply be passed via the command line, similar to the base model training below. 

### Training the base models

Cityscapes diffusion model
```
python3 src/firespreadscenarios/run_diffusion_generic.py -c cfgs/cityscapes/base_config_image_cond.yaml --data cfgs/cityscapes/dataset.yaml --trainer cfgs/cityscapes/trainer.yaml
```

Cityscapes Prob. UNet
```
python3 src/firespreadscenarios/run_PUNet_generic.py -c cfgs/cityscapes/PUNet.yaml --data cfgs/cityscapes/dataset.yaml --trainer cfgs/cityscapes/PUNet_trainer.yaml
```

MMFire diffusion model
```
python3 src/firespreadscenarios/run_diffusion_generic.py --trainer=cfgs/simfire/trainer.yaml --data=cfgs/simfire/dataset.yaml --config=cfgs/simfire/base_config_image_cond.yaml --trainer.max_epochs=1000
```

MMFire Prob. UNet
```
python3 src/firespreadscenarios/run_PUNet_generic.py --trainer=cfgs/simfire/PUNet_trainer.yaml --data=cfgs/simfire/dataset.yaml --config=cfgs/simfire/PUNet.yaml 
```

LIDC diffusion model
```
python3 src/firespreadscenarios/run_diffusion_generic.py -c cfgs/LIDC/base_config_image_cond.yaml --data cfgs/LIDC/dataset.yaml --trainer cfgs/LIDC/trainer.yaml --model.train_p_log_mean=1
```

LIDC Prob. UNet
```
python3 src/firespreadscenarios/run_PUNet_generic.py --trainer=cfgs/LIDC/PUNet_trainer.yaml --data=cfgs/LIDC/dataset.yaml --config=cfgs/LIDC/PUNet.yaml 
```


## Citation

```
@inproceedings{
gerard2025wildfire,
title={Wildfire Spread Scenarios: Increasing Sample Diversity of Segmentation Diffusion Models with Training-Free Methods},
author={Sebastian Gerard and Josephine Sullivan},
booktitle={Northern Lights Deep Learning Conference 2026},
year={2025},
url={https://openreview.net/forum?id=E44d5hzEV0}
}
```
